{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10255895,"sourceType":"datasetVersion","datasetId":6344269}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport lightgbm as lgb\nfrom lightgbm import early_stopping, log_evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load datasets\ntrain_path = '/kaggle/input/credit-score-classification/train.csv'\ntest_path = '/kaggle/input/credit-score-classification/test.csv'\n\ntrain_data = pd.read_csv('/kaggle/input/credit-score-classification/train.csv', low_memory=False)\ntest_data = pd.read_csv('/kaggle/input/credit-score-classification/test.csv', low_memory=False)\n\n# Debug column names\nprint(\"Train Data Columns:\", train_data.columns)\nprint(\"Test Data Columns:\", test_data.columns)\n\n# Clean column names\ntrain_data.columns = train_data.columns.str.strip()\ntest_data.columns = test_data.columns.str.strip()\n\n# Verify if target column exists\nif 'Credit_Score' not in train_data.columns:\n    raise KeyError(\"The target column 'Credit_Score' is missing in the training data.\")\n\n# Preprocessing\n# Handle mixed types\nfor col in train_data.columns:\n    if train_data[col].dtype == 'object':\n        train_data[col] = train_data[col].astype(str)\n        if col in test_data.columns:\n            test_data[col] = test_data[col].astype(str)\n\n# Fill missing values\ntrain_data.fillna(-999, inplace=True)\ntest_data.fillna(-999, inplace=True)\n\n# Encode categorical features\ncategorical_columns = train_data.select_dtypes(include=['object']).columns\nlabel_encoders = {}\n\nfor col in categorical_columns:\n    if col != 'Credit_Score':  # Skip the target column\n        le = LabelEncoder()\n        combined_data = pd.concat([train_data[col], test_data[col]], axis=0)\n        le.fit(combined_data.astype(str))\n        train_data[col] = le.transform(train_data[col].astype(str))\n        if col in test_data.columns:\n            test_data[col] = le.transform(test_data[col].astype(str))\n        label_encoders[col] = le\n\n# Encode target variable\ntarget_encoder = LabelEncoder()\ntrain_data['Credit_Score'] = target_encoder.fit_transform(train_data['Credit_Score'])\n\n# Feature-target split\nX = train_data.drop(columns=['Credit_Score'])\ny = train_data['Credit_Score']\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# LightGBM Dataset\ntrain_dataset = lgb.Dataset(X_train, label=y_train)\nval_dataset = lgb.Dataset(X_val, label=y_val, reference=train_dataset)\n\n# LightGBM parameters\nparams = {\n    'objective': 'multiclass',\n    'num_class': len(target_encoder.classes_),\n    'boosting_type': 'gbdt',\n    'metric': 'multi_logloss',\n    'learning_rate': 0.05,\n    'num_leaves': 31,\n    'feature_fraction': 0.8,\n}\n\n# Train LightGBM model\n# Train LightGBM model with proper callbacks\nlgbm_model = lgb.train(\n    params,\n    train_dataset,\n    num_boost_round=1000,\n    valid_sets=[train_dataset, val_dataset],\n    callbacks=[\n        early_stopping(stopping_rounds=50),  # Early stopping callback\n        log_evaluation(100),  # Log evaluation every 100 rounds\n    ],\n)\n\n# Evaluate model\ny_val_pred = lgbm_model.predict(X_val)\ny_val_pred_classes = y_val_pred.argmax(axis=1)\n\nprint(\"Classification Report:\")\nprint(classification_report(y_val, y_val_pred_classes, target_names=target_encoder.classes_))\n\n# AUC Score\nauc = roc_auc_score(pd.get_dummies(y_val), y_val_pred, multi_class=\"ovr\")\nprint(f\"Validation AUC Score: {auc:.4f}\")\n\n# Predict test set\nif 'Credit_Score' in test_data.columns:\n    test_data = test_data.drop(columns=['Credit_Score'])  # Drop target if it exists in test\n\ntest_predictions = lgbm_model.predict(test_data)\ntest_classes = test_predictions.argmax(axis=1)\ntest_data['Predicted_Credit_Score'] = target_encoder.inverse_transform(test_classes)\n\n# Save results to a writable directory\ntest_data[['Predicted_Credit_Score']].to_csv('/kaggle/working/predicted_credit_scores.csv', index=False)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-20T18:17:49.865448Z","iopub.execute_input":"2024-12-20T18:17:49.865822Z","iopub.status.idle":"2024-12-20T18:18:22.945764Z","shell.execute_reply.started":"2024-12-20T18:17:49.865797Z","shell.execute_reply":"2024-12-20T18:18:22.944581Z"}},"outputs":[{"name":"stdout","text":"Train Data Columns: Index(['ID', 'Customer_ID', 'Month', 'Name', 'Age', 'SSN', 'Occupation',\n       'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',\n       'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan',\n       'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit',\n       'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt',\n       'Credit_Utilization_Ratio', 'Credit_History_Age',\n       'Payment_of_Min_Amount', 'Total_EMI_per_month',\n       'Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance',\n       'Credit_Score'],\n      dtype='object')\nTest Data Columns: Index(['ID', 'Customer_ID', 'Month', 'Name', 'Age', 'SSN', 'Occupation',\n       'Annual_Income', 'Monthly_Inhand_Salary', 'Num_Bank_Accounts',\n       'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Type_of_Loan',\n       'Delay_from_due_date', 'Num_of_Delayed_Payment', 'Changed_Credit_Limit',\n       'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt',\n       'Credit_Utilization_Ratio', 'Credit_History_Age',\n       'Payment_of_Min_Amount', 'Total_EMI_per_month',\n       'Amount_invested_monthly', 'Payment_Behaviour', 'Monthly_Balance'],\n      dtype='object')\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013001 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5220\n[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 27\n[LightGBM] [Info] Start training from score -1.721697\n[LightGBM] [Info] Start training from score -1.241156\n[LightGBM] [Info] Start training from score -0.630759\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's multi_logloss: 0.619463\tvalid_1's multi_logloss: 0.647037\n[200]\ttraining's multi_logloss: 0.571046\tvalid_1's multi_logloss: 0.621006\n[300]\ttraining's multi_logloss: 0.533143\tvalid_1's multi_logloss: 0.601623\n[400]\ttraining's multi_logloss: 0.501356\tvalid_1's multi_logloss: 0.586432\n[500]\ttraining's multi_logloss: 0.472027\tvalid_1's multi_logloss: 0.571977\n[600]\ttraining's multi_logloss: 0.44704\tvalid_1's multi_logloss: 0.560633\n[700]\ttraining's multi_logloss: 0.424592\tvalid_1's multi_logloss: 0.551858\n[800]\ttraining's multi_logloss: 0.404435\tvalid_1's multi_logloss: 0.544044\n[900]\ttraining's multi_logloss: 0.385733\tvalid_1's multi_logloss: 0.536742\n[1000]\ttraining's multi_logloss: 0.368829\tvalid_1's multi_logloss: 0.530942\nDid not meet early stopping. Best iteration is:\n[1000]\ttraining's multi_logloss: 0.368829\tvalid_1's multi_logloss: 0.530942\nClassification Report:\n              precision    recall  f1-score   support\n\n        Good       0.75      0.74      0.75      3527\n        Poor       0.78      0.76      0.77      5874\n    Standard       0.79      0.81      0.80     10599\n\n    accuracy                           0.78     20000\n   macro avg       0.77      0.77      0.77     20000\nweighted avg       0.78      0.78      0.78     20000\n\nValidation AUC Score: 0.9107\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}